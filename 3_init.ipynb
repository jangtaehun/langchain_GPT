{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv3는 \"You Only Look Once version 3\"의 약자로, 실시간 객체 감지를 위한 딥러닝 알고리즘입니다. YOLOv3는 이미지나 비디오에서 다양한 객체를 탐지하고 분류하는 데 사용되며, 컴퓨터 비전 및 자율 주행 자동차와 같은 응용 프로그램에서 널리 사용됩니다.\n",
      "YOLOv5는 실시간 객체 탐지 모델인 You Only Look Once(한 번만 보기)의 5번째 버전을 의미합니다. YOLOv5는 빠르고 정확한 객체 탐지를 위한 딥러닝 알고리즘으로, 컴퓨터 비전 및 인공지능 분야에서 널리 사용됩니다.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\")\n",
    "chat = ChatOpenAI() # temperature=0.5, max_tokens=100 -> 창의성, 길이\n",
    "\n",
    "a = llm.predict(\"YOLOv3가 뭐야\")\n",
    "b = chat.predict(\"YOLOv5가 뭐야\")\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='YOLOv8는 You Only Look Once (YOLO)라고 불리는 객체 감지 알고리즘의 최신 버전 중 하나입니다. YOLO는 이미지나 비디오에서 여러 객체를 실시간으로 감지하는 데 사용되는 딥러닝 알고리즘입니다. YOLOv8은 YOLO 시리즈의 최신 버전 중 하나로, 이전 버전들보다 높은 정확도와 빠른 속도를 제공하도록 개선되었습니다. YOLOv8은 객체 감지 및 추적 등 다양한 컴퓨터 비전 작업에 널리 사용되고 있습니다.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content = \"당신은 AI 전문가 입니다.\"),\n",
    "    AIMessage(content = \"안녕하세요. AI에 관해 궁금한 것이 있다면 물어보세요.\"),\n",
    "    HumanMessage(content = \"YOLOv8이 뭐야\"),\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YOLOv3와 YOLOv5는 모두 객체 감지 알고리즘인 YOLO(You Only Look Once)의 버전이지만, 몇 가지 중요한 차이점이 있습니다.\\n\\n1. 모델 구조:\\n- YOLOv3: Darknet-53 백본 네트워크를 사용하여 53개의 합성곱 레이어로 구성되어 있습니다.\\n- YOLOv5: YOLOv5는 PyTorch를 기반으로 하며, 더 간단한 네트워크 구조를 가지고 있습니다. YOLOv5는 YOLOv3보다 더 가볍고 빠르게 작동합니다.\\n\\n2. 데이터 증강:\\n- YOLOv3: 데이터 증강 기술이 제한적이며, 모델의 성능을 향상시키는 데 한계가 있습니다.\\n- YOLOv5: YOLOv5는 더 많은 데이터 증강 기술을 적용하여 모델의 성능을 향상시킵니다. 이는 모델의 정확도를 높이는 데 도움이 됩니다.\\n\\n3. 학습 방법:\\n- YOLOv3: 전체 데이터셋에 대해 한 번에 학습을 시키는 end-to-end 방식을 사용합니다.\\n- YOLOv5: YOLOv5는 데이터셋을 미니배치로 나누어 학습을 시키는 방식을 사용합니다. 이는 모델의 학습 속도를 높이는 데 도움이 됩니다.\\n\\n요약하면, YOLOv5는 YOLOv3보다 더 가벼우면서도 더 높은 정확도를 제공하는 모델이며, 데이터 증강 기술과 학습 방법에 있어서 더 나은 성능을 보입니다.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "template = PromptTemplate.from_template(\"{model_a}과 {model_b}의 차이점을 설명해주세요.\")\n",
    "prompt = template.format(model_a=\"YOLOv3\", model_b=\"YOLOv5\")\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='YOLOv3와 YOLOv5는 모두 객체 감지를 위한 딥러닝 알고리즘인 YOLO(You Only Look Once)의 다른 버전입니다. 각각의 주요 차이점은 다음과 같습니다:\\n\\n1. 모델 구조:\\n   - YOLOv3: YOLOv3는 Darknet 프레임워크에서 구현된 버전으로, Darknet-53 백본 네트워크를 사용합니다. YOLOv3는 53개의 합성곱 레이어로 구성되어 있고, 세 가지 다른 크기의 그리드를 사용하여 객체를 감지합니다.\\n   - YOLOv5: YOLOv5는 PyTorch를 기반으로 한 버전으로, 좀 더 간단한 구조를 가지고 있습니다. YOLOv5는 CSPDarknet 백본 네트워크를 사용하며, 경량화 및 빠른 학습을 위해 최적화되었습니다.\\n\\n2. 학습 방식:\\n   - YOLOv3: YOLOv3는 전체 데이터셋에 대해 한 번에 학습하는 방식을 사용합니다. 이는 학습 시간이 오래 걸리고, 데이터셋이 큰 경우에는 학습이 어려울 수 있습니다.\\n   - YOLOv5: YOLOv5는 Transfer Learning을 사용하여 사전 학습된 모델을 기반으로 새로운 데이터셋에 대해 미세 조정하는 방식을 사용합니다. 이는 빠른 학습과 좀 더 작은 데이터셋에서도 좋은 성능을 보여줍니다.\\n\\n3. 성능:\\n   - YOLOv3: YOLOv3는 이미지 분류 및 객체 감지에서 좋은 성능을 보여주는 안정적인 모델입니다.\\n   - YOLOv5: YOLOv5는 YOLOv3에 비해 경량화 및 빠른 학습을 통해 높은 정확도를 유지하면서도 더 빠른 속도로 객체 감지를 수행할 수 있습니다.\\n\\n요약하면, YOLOv3는 안정적이고 성능이 좋은 모델이며, YOLOv5는 경량화 및 빠른 학습을 통해 높은 정확도와 빠른 속도를 제공하는 모델입니다.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 {word} 전문가 입니다.\"),\n",
    "        (\"ai\", \"안녕하세요. AI에 관해 궁금한 것이 있다면 물어보세요.\"),\n",
    "        (\"human\", \"{model_a}와/과 {model_b}의 차이점을 설명해주세요.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    word=\"ai\",\n",
    "    model_a=\"YOLOv3\", \n",
    "    model_b=\"YOLOv5\"\n",
    ")\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['파이썬은 아름다운 언어',\n",
       " '간결하고 강력한 문법으로 빛나는 보석',\n",
       " '코딩을 즐겁게 만들어주는 파이썬',\n",
       " '프로그래밍 세계의 신비를 열어주는 열쇠.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 프로그래밍 언어에 대한 시를 쓰는 시 전문가 입니다. 입력 받은 질문들은 모두 comma로 구분된 list로 답해질 것입니다.\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    question=\"파이썬, \"\n",
    ")\n",
    "result = chat.predict_messages(prompt)\n",
    "p = CommaOutputParser()\n",
    "p.parse(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아름다운 파이썬', '간결하고도 풍부한', '문법은 우아하고', '다양한 라이브러리로 빛나네.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 프로그래밍 언어에 대한 시를 쓰는 시 전문가 입니다. 입력 받은 질문들은 모두 comma로 구분된 list로 답해질 것입니다.\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = template | chat | CommaOutputParser()\n",
    "chain.invoke({\"question\":\"파이썬\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬이여, 그대의 매력은\n",
      "간결하고 아름다운 문법 속에 담겨\n",
      "들여다보면 마치 마법처럼\n",
      "문제를 해결해주는 그 힘이여\n",
      "\n",
      "인터프리터 언어로 탄생한 그 순간\n",
      "세계는 변했고 우리는 편안했네파이썬이여, 그대의 매력은\n",
      "간결하고 아름다운 문법 속에 담겨\n",
      "들여다보면 마치 마법처럼\n",
      "문제를 해결해주는 그 힘이여\n",
      "\n",
      "인터프리터 언어로 탄생한 그 순간\n",
      "세계는 변했고 우리는 편안했네\n",
      "\n",
      "해석:\n",
      "이 시는 파이썬이라는 프로그래밍 언어의 매력을 표현하고 있습니다. 파이썬은 간결하고 아름다운 문법을 가지고 있으며, 문제를 해결해주는 마법 같은 힘이 있다고 표현되어 있습니다. 또한, 파이썬이 인터프리터 언어로 탄생한 순간을 회고하며 세계가 변화하고 우리가 편안해진다는 감정을 담고 있습니다."
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5, streaming=True, callbacks=[StreamingStdOutCallbackHandler()]) # streaming=True -> 응답 생성을 확인할 수 있다.\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "    \n",
    "make_poem = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 프로그래밍 언어에 대한 시를 쓰는 시 전문가 입니다. 적어도 6줄 이상의 시를 만들어줘. 입력 받은 질문들은 모두 comma로 구분된 list로 답해질 것입니다.\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "explain_poem = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 프로그래밍 언어에 대한 시를 해석해주는 시 해석 전문가 입니다. 입력받은 시를 알려주고 한 줄 띄고 시를 해석해주세요. 입력 받은 질문들은 모두 comma로 구분된 list로 답해질 것입니다.\"),\n",
    "        (\"human\", \"{poem}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "make_poem_chain = make_poem | chat\n",
    "explain_poem_chain = explain_poem | chat\n",
    "final_chain = {\"poem\":make_poem_chain}| explain_poem_chain\n",
    "\n",
    "'''\n",
    "poem_result = make_poem_chain.invoke({\"question\": \"파이썬\"})\n",
    "print(\"생성된 시:\", poem_result)\n",
    "\n",
    "invoke_result = explain_poem_chain.invoke({\"poem\": poem_result})\n",
    "print(\"시 해석:\", invoke_result)\n",
    "'''\n",
    "\n",
    "invoke_result = final_chain.invoke({\"question\":\"파이썬\"})\n",
    "# invoke_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
