{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ultralitics YOLOv3의 특징을 자세히 알려줘'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "t = PromptTemplate(\n",
    "    template=\"Ultralitics {model}의 특징을 자세히 알려줘\",\n",
    "    input_variables=[\"model\"],\n",
    ")\n",
    "t.format(model=\"YOLOv3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Region Proposal Network (RPN): Faster R-CNN은 Region Proposal Network (RPN)을 사용하여 이미지 내에서 객체가 존재할 가능성이 있는 영역을 제안한다. 이를 통해 더 빠르고 정확한 객체 검출이 가능해진다.\n",
      "\n",
      "2. Region of Interest (RoI) Pooling: Faster R-CNN은 RoI Pooling을 사용하여 각 객체 제안 영역을 동일한 크기의 특징 맵으로 변환하여 객체 분류와 위치 결정을 수행한다.\n",
      "\n",
      "3. Two-stage detection: Faster R-CNN은 두 단계의 검출 과정을 거친다. 먼저 RPN을 사용하여 객체 제안을 생성하고, 이후 RoI Pooling을 사용하여 객체 분류와 위치 결정을 수행한다.\n",
      "\n",
      "4. End-to-end 학습: Faster R-CNN은 end-to-end 방식으로 학습이 가능하다. 객체 검출을 위한 모델 전체가 하나의 신경망으로 연결되어 있어 최적화가 더욱 효율적으로 이루어진다.\n",
      "\n",
      "5. 높은 정확도: Faster R-CNN은 기존의 객체 검출 방법들에 비해 더 높은 정확도를 보여준다. 이는 RPN을 사용하여 더 정확한 객체 제안을 생성하고, RoI Pooling을 통해 정확한 객체 위치를 결정하기 때문이다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1. Region Proposal Network (RPN): Faster R-CNN은 Region Proposal Network (RPN)을 사용하여 이미지 내에서 객체가 존재할 가능성이 있는 영역을 제안한다. 이를 통해 더 빠르고 정확한 객체 검출이 가능해진다.\\n\\n2. Region of Interest (RoI) Pooling: Faster R-CNN은 RoI Pooling을 사용하여 각 객체 제안 영역을 동일한 크기의 특징 맵으로 변환하여 객체 분류와 위치 결정을 수행한다.\\n\\n3. Two-stage detection: Faster R-CNN은 두 단계의 검출 과정을 거친다. 먼저 RPN을 사용하여 객체 제안을 생성하고, 이후 RoI Pooling을 사용하여 객체 분류와 위치 결정을 수행한다.\\n\\n4. End-to-end 학습: Faster R-CNN은 end-to-end 방식으로 학습이 가능하다. 객체 검출을 위한 모델 전체가 하나의 신경망으로 연결되어 있어 최적화가 더욱 효율적으로 이루어진다.\\n\\n5. 높은 정확도: Faster R-CNN은 기존의 객체 검출 방법들에 비해 더 높은 정확도를 보여준다. 이는 RPN을 사용하여 더 정확한 객체 제안을 생성하고, RoI Pooling을 통해 정확한 객체 위치를 결정하기 때문이다.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "chat.predict(\"Faster R-CNN의 특징은 뭐야\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "{\n",
    "\"question\": \"Faster R-CNN의 특징은 뭐야\",\n",
    "\"answer\": \"\"\"\n",
    "◦ 특징:\n",
    "1. Region Proposal Network (RPN) 사용: CNN 기반 RPN을 활용하여 관심 영역을 빠르게 생성함.\n",
    "2. End-to-End 학습 가능: Region Proposal과 Classification을 하나의 네트워크에서 학습할 수 있음.\n",
    "3. Feature Map 공유: Backbone CNN을 공유하여 연산량을 줄이고 속도를 개선함.\n",
    "4. Anchor Box 활용: 다양한 크기의 객체를 탐지할 수 있도록 앵커 박스를 사용함.,\n",
    "\n",
    "◦ 구조:\n",
    "1. Backbone CNN (ResNet, VGG 등) → Feature Map 생성\n",
    "2. Region Proposal Network (RPN) → 관심 영역(Region Proposal) 예측\n",
    "3. ROI Pooling → 관심 영역을 동일한 크기로 변환\n",
    "4. Fully Connected Layers → Classification + Bounding Box Regression 수행,\n",
    "\n",
    "◦ 성능 비교:\n",
    "- 정확도: Faster R-CNN은 YOLO보다 높은 정확도를 가짐.\n",
    "- 속도: YOLO, SSD에 비해 느리지만 Fast R-CNN보다 빠름.\n",
    "- 활용: 실시간 처리보다는 높은 정확도를 요구하는 객체 탐지에서 활용됨.,\"\"\"\n",
    "},\n",
    "\n",
    "{\n",
    "\"question\": \"SSD의 특징은 뭐야?\",\n",
    "\"answer\": \"\"\"\n",
    "◦ 특징:\n",
    "1. One-stage Detector: Region Proposal 없이 단 한 번의 Forward Pass로 객체 탐지를 수행함. 속도가 빠르고 실시간 탐지가 가능함\n",
    "2. Multi-scale Feature Maps: 여러 계층의 Feature Map에서 Bounding Box를 예측하여 다양한 크기의 객체 탐지 가능, 작은 객체 탐지를 개선하기 위해 저해상도 + 고해상도 Feature Map을 활용함.\n",
    "3. Anchor Box 활용: Faster R-CNN과 유사하게 다양한 크기와 비율의 앵커 박스(기본 박스)를 사용하여 여러 객체를 동시에 탐지함. 하지만 RPN을 사용하지 않고 CNN이 직접 여러 박스를 예측함.\n",
    "4. End-to-End 학습 가능: Faster R-CNN과 달리 별도의 RPN 없이 단일 네트워크로 객체 탐지와 분류를 동시에 학습 가능함.\n",
    "\n",
    "◦ 구조:\n",
    "1. Backbone CNN (ResNet, VGG 등) → Feature Map 생성\n",
    "2. Multi-scale Feature Maps 활용 → 다양한 크기의 객체를 감지하기 위해 여러 층의 Feature Map을 사용\n",
    "3. Anchor Box 기반 예측 → 각 Feature Map의 셀에서 여러 개의 Bounding Box를 동시에 예측\n",
    "4. Non-Maximum Suppression (NMS) → 중복된 Bounding Box를 제거하여 최종 탐지 결과 출력\n",
    "\n",
    "◦ 성능 비교:\n",
    "- 정확도: Faster R-CNN보다 약간 낮지만, YOLO보다는 비슷하거나 높은 성능을 보임.\n",
    "- 속도: Faster R-CNN보다 빠르며, YOLO보다는 약간 느릴 수 있음.\n",
    "- 활용: 실시간 객체 탐지(자율주행, 감시 시스템 등)에 적합하며, 속도와 정확도 균형이 필요할 때 유용함.\n",
    "\"\"\",\n",
    "},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "◦ 특징:\n",
      "1. One-stage Detector: Region Proposal 없이 한 번의 Forward Pass로 객체 탐지를 수행함. 이로 인해 빠른 속도를 제공함.\n",
      "2. Grid Cell 기반 객체 탐지: 이미지를 그리드 셀로 나누어 각 셀에서 객체의 경계 상자와 클래스 확률을 예측함.\n",
      "3. Multi-scale Prediction: 다양한 크기의 객체를 탐지하기 위해 다양한 스케일의 Feature Map을 사용함.\n",
      "4. Darknet-53 백본 네트워크: 경량화된 네트워크 구조인 Darknet-53을 사용하여 높은 정확도와 빠른 속도를 동시에 제공함.\n",
      "5. 다양한 모델 크기 제공: YOLOv3는 다양한 모델 크기를 제공하여 정확도와 속도를 조절할 수 있음.\n",
      "\n",
      "◦ 구조:\n",
      "1. Darknet-53 Backbone Network → Feature Map 생성\n",
      "2. Detection Layer → Grid Cell을 기반으로 객체의 경계 상자와 클래스 확률을 예측\n",
      "3. Non-Maximum Suppression (NMS) → 중복된 경계 상자를 제거하여 최종 탐지 결과 출력\n",
      "\n",
      "◦ 성능 비교:\n",
      "- 정확도: SSD보다 높은 정확도를 보이며, 속도도 빠름.\n",
      "- 속도: Faster R-CNN, SSD에 비해 빠른 속도를 제공함.\n",
      "- 활용: 실시간 객체 탐지에 적합하며, 빠른 속도와 높은 정확도를 동시에 요구하는 경우에 유용함."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\n◦ 특징:\\n1. One-stage Detector: Region Proposal 없이 한 번의 Forward Pass로 객체 탐지를 수행함. 이로 인해 빠른 속도를 제공함.\\n2. Grid Cell 기반 객체 탐지: 이미지를 그리드 셀로 나누어 각 셀에서 객체의 경계 상자와 클래스 확률을 예측함.\\n3. Multi-scale Prediction: 다양한 크기의 객체를 탐지하기 위해 다양한 스케일의 Feature Map을 사용함.\\n4. Darknet-53 백본 네트워크: 경량화된 네트워크 구조인 Darknet-53을 사용하여 높은 정확도와 빠른 속도를 동시에 제공함.\\n5. 다양한 모델 크기 제공: YOLOv3는 다양한 모델 크기를 제공하여 정확도와 속도를 조절할 수 있음.\\n\\n◦ 구조:\\n1. Darknet-53 Backbone Network → Feature Map 생성\\n2. Detection Layer → Grid Cell을 기반으로 객체의 경계 상자와 클래스 확률을 예측\\n3. Non-Maximum Suppression (NMS) → 중복된 경계 상자를 제거하여 최종 탐지 결과 출력\\n\\n◦ 성능 비교:\\n- 정확도: SSD보다 높은 정확도를 보이며, 속도도 빠름.\\n- 속도: Faster R-CNN, SSD에 비해 빠른 속도를 제공함.\\n- 활용: 실시간 객체 탐지에 적합하며, 빠른 속도와 높은 정확도를 동시에 요구하는 경우에 유용함.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "# Fewshot: 모델에게 예제를 보여주고 이에 대한 답변을 요청하는 방식\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "example_template = \"\"\"\n",
    "    Human: {question}\n",
    "    AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples = examples,\n",
    "    suffix=\"Human: {model}의 특징은 뭐야\", # suffix는 프롬프트의 마지막 부분을 지정하는 역할 -> Few-shot Prompt 예제가 제공된 후 실제 입력값(질문)이 들어가는 위치를 지정\n",
    "    input_variables=[\"model\"] # 사용자로부터 입력받을 변수를 지정하는 역할\n",
    ")\n",
    "\n",
    "chain = prompt | chat\n",
    "chain.invoke({\n",
    "    \"model\": \"YOLOv3\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "{\n",
    "\"question\": \"Faster R-CNN\",\n",
    "\"answer\": \"\"\"\n",
    "◦ 특징:\n",
    "1. Region Proposal Network (RPN) 사용: CNN 기반 RPN을 활용하여 관심 영역을 빠르게 생성함.\n",
    "2. End-to-End 학습 가능: Region Proposal과 Classification을 하나의 네트워크에서 학습할 수 있음.\n",
    "3. Feature Map 공유: Backbone CNN을 공유하여 연산량을 줄이고 속도를 개선함.\n",
    "4. Anchor Box 활용: 다양한 크기의 객체를 탐지할 수 있도록 앵커 박스를 사용함.,\n",
    "\n",
    "◦ 구조:\n",
    "1. Backbone CNN (ResNet, VGG 등) → Feature Map 생성\n",
    "2. Region Proposal Network (RPN) → 관심 영역(Region Proposal) 예측\n",
    "3. ROI Pooling → 관심 영역을 동일한 크기로 변환\n",
    "4. Fully Connected Layers → Classification + Bounding Box Regression 수행,\n",
    "\n",
    "◦ 성능 비교:\n",
    "- 정확도: Faster R-CNN은 YOLO보다 높은 정확도를 가짐.\n",
    "- 속도: YOLO, SSD에 비해 느리지만 Fast R-CNN보다 빠름.\n",
    "- 활용: 실시간 처리보다는 높은 정확도를 요구하는 객체 탐지에서 활용됨.,\"\"\"\n",
    "},\n",
    "\n",
    "{\n",
    "\"question\": \"SSD\",\n",
    "\"answer\": \"\"\"\n",
    "◦ 특징:\n",
    "1. One-stage Detector: Region Proposal 없이 단 한 번의 Forward Pass로 객체 탐지를 수행함. 속도가 빠르고 실시간 탐지가 가능함\n",
    "2. Multi-scale Feature Maps: 여러 계층의 Feature Map에서 Bounding Box를 예측하여 다양한 크기의 객체 탐지 가능, 작은 객체 탐지를 개선하기 위해 저해상도 + 고해상도 Feature Map을 활용함.\n",
    "3. Anchor Box 활용: Faster R-CNN과 유사하게 다양한 크기와 비율의 앵커 박스(기본 박스)를 사용하여 여러 객체를 동시에 탐지함. 하지만 RPN을 사용하지 않고 CNN이 직접 여러 박스를 예측함.\n",
    "4. End-to-End 학습 가능: Faster R-CNN과 달리 별도의 RPN 없이 단일 네트워크로 객체 탐지와 분류를 동시에 학습 가능함.\n",
    "\n",
    "◦ 구조:\n",
    "1. Backbone CNN (ResNet, VGG 등) → Feature Map 생성\n",
    "2. Multi-scale Feature Maps 활용 → 다양한 크기의 객체를 감지하기 위해 여러 층의 Feature Map을 사용\n",
    "3. Anchor Box 기반 예측 → 각 Feature Map의 셀에서 여러 개의 Bounding Box를 동시에 예측\n",
    "4. Non-Maximum Suppression (NMS) → 중복된 Bounding Box를 제거하여 최종 탐지 결과 출력\n",
    "\n",
    "◦ 성능 비교:\n",
    "- 정확도: Faster R-CNN보다 약간 낮지만, YOLO보다는 비슷하거나 높은 성능을 보임.\n",
    "- 속도: Faster R-CNN보다 빠르며, YOLO보다는 약간 느릴 수 있음.\n",
    "- 활용: 실시간 객체 탐지(자율주행, 감시 시스템 등)에 적합하며, 속도와 정확도 균형이 필요할 때 유용함.\n",
    "\"\"\",\n",
    "},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "◦ 특징:\n",
      "1. One-stage Detector: 전체 이미지를 한 번에 처리하여 객체 탐지를 수행함. 이를 통해 빠른 속도와 실시간 탐지가 가능함.\n",
      "2. Darknet-53 Backbone: Darknet 아키텍처를 기반으로 한 더 깊고 강력한 CNN 모델인 Darknet-53을 사용하여 높은 정확도를 달성함.\n",
      "3. Feature Pyramid Network (FPN) 사용: 다양한 크기의 객체를 탐지하기 위해 다중 스케일의 Feature Map을 결합하여 객체를 탐지함.\n",
      "4. Anchor Box 및 Grid Cell 기반 탐지: 이미지를 그리드로 나누어 각 셀에서 객체의 존재 여부와 Bounding Box를 예측함.\n",
      "\n",
      "◦ 구조:\n",
      "1. Darknet-53 Backbone → 다양한 크기의 Feature Map 생성\n",
      "2. YOLO Layer: 각 층에서 객체의 존재 여부, 클래스 확률, Bounding Box 정보를 예측\n",
      "3. Feature Pyramid Network (FPN) 결합 → 다중 스케일의 Feature Map을 결합하여 다양한 크기의 객체를 탐지\n",
      "4. Non-Maximum Suppression (NMS) → 중복된 Bounding Box를 제거하여 최종 탐지 결과 출력\n",
      "\n",
      "◦ 성능 비교:\n",
      "- 정확도: SSD, Faster R-CNN에 비해 더 높은 정확도를 보임.\n",
      "- 속도: SSD, Faster R-CNN에 비해 빠르며, 실시간 객체 탐지에 적합함.\n",
      "- 활용: 실시간 객체 탐지 및 높은 정확도가 요구되는 다양한 응용 분야에 활용됨."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\n◦ 특징:\\n1. One-stage Detector: 전체 이미지를 한 번에 처리하여 객체 탐지를 수행함. 이를 통해 빠른 속도와 실시간 탐지가 가능함.\\n2. Darknet-53 Backbone: Darknet 아키텍처를 기반으로 한 더 깊고 강력한 CNN 모델인 Darknet-53을 사용하여 높은 정확도를 달성함.\\n3. Feature Pyramid Network (FPN) 사용: 다양한 크기의 객체를 탐지하기 위해 다중 스케일의 Feature Map을 결합하여 객체를 탐지함.\\n4. Anchor Box 및 Grid Cell 기반 탐지: 이미지를 그리드로 나누어 각 셀에서 객체의 존재 여부와 Bounding Box를 예측함.\\n\\n◦ 구조:\\n1. Darknet-53 Backbone → 다양한 크기의 Feature Map 생성\\n2. YOLO Layer: 각 층에서 객체의 존재 여부, 클래스 확률, Bounding Box 정보를 예측\\n3. Feature Pyramid Network (FPN) 결합 → 다중 스케일의 Feature Map을 결합하여 다양한 크기의 객체를 탐지\\n4. Non-Maximum Suppression (NMS) → 중복된 Bounding Box를 제거하여 최종 탐지 결과 출력\\n\\n◦ 성능 비교:\\n- 정확도: SSD, Faster R-CNN에 비해 더 높은 정확도를 보임.\\n- 속도: SSD, Faster R-CNN에 비해 빠르며, 실시간 객체 탐지에 적합함.\\n- 활용: 실시간 객체 탐지 및 높은 정확도가 요구되는 다양한 응용 분야에 활용됨.')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "# examples 리스트에는 \"question\"과 \"answer\" 키 사용\n",
    "example_prompt_1 = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{question}의 특징이 뭐야?\"),\n",
    "    (\"ai\", \"{answer}\")\n",
    "])\n",
    "\n",
    "example_prompt_2 = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_prompt_1,\n",
    "    examples = examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 ai 전문가입니다. 주어진 형식에 맞춰 설명해주세요.\"),\n",
    "    example_prompt_2,\n",
    "    (\"human\", \"{question}의 특징이 뭐야?\"),\n",
    "])\n",
    "\n",
    "chain = final_prompt | chat\n",
    "chain.invoke({\n",
    "    \"question\": \"YOLOv3\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FewShot PromptTemplate -> 일반적인 프롬프트(텍스트 기반)\n",
    "> - 일반 텍스트 기반\n",
    "> - 단순한 텍스트 템플릿\n",
    "> - 일부 모델에 적합\n",
    "\n",
    "### FewShot ChatMessage PromptTemplate -> 대화형 프롬프트(ChatGPT 등 Chat API)\n",
    "> - Chat message 기반\n",
    "> - system, human, ai 구분\n",
    "> - 시스템 메시지를 통해 역할 부여 가능\n",
    "> - OpenAI Chat 모델 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FewShotPromptTemplate에 example_selector 적용\n",
    "> - FewShotPromptTemplate을 사용할 때, example_selector를 활용하여 랜덤으로 예제를 선택\n",
    "> - 예제 수가 많을 때: 모든 예제를 포함하는 대신 몇 개의 대표 예제만 선택하여 모델이 참고하도록 할 수 있음.\n",
    "> - 매번 다른 Few-shot 학습을 유도할 때: LLM이 항상 동일한 예제를 참고하지 않도록 다양성을 줄 수 있음.\n",
    "> - 다양한 모델명을 입력할 때도 일반화가 필요할 경우: 특정 예제에 과적합되지 않고 다양한 답변을 생성할 수 있도록 유도 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "{\n",
    "\"question\": \"Faster R-CNN의 특징은 뭐야\",\n",
    "\"answer\": \"\"\"\n",
    "◦ 특징:\n",
    "1. Region Proposal Network (RPN) 사용: CNN 기반 RPN을 활용하여 관심 영역을 빠르게 생성함.\n",
    "2. End-to-End 학습 가능: Region Proposal과 Classification을 하나의 네트워크에서 학습할 수 있음.\n",
    "3. Feature Map 공유: Backbone CNN을 공유하여 연산량을 줄이고 속도를 개선함.\n",
    "4. Anchor Box 활용: 다양한 크기의 객체를 탐지할 수 있도록 앵커 박스를 사용함.,\n",
    "\n",
    "◦ 구조:\n",
    "1. Backbone CNN (ResNet, VGG 등) → Feature Map 생성\n",
    "2. Region Proposal Network (RPN) → 관심 영역(Region Proposal) 예측\n",
    "3. ROI Pooling → 관심 영역을 동일한 크기로 변환\n",
    "4. Fully Connected Layers → Classification + Bounding Box Regression 수행,\n",
    "\n",
    "◦ 성능 비교:\n",
    "- 정확도: Faster R-CNN은 YOLO보다 높은 정확도를 가짐.\n",
    "- 속도: YOLO, SSD에 비해 느리지만 Fast R-CNN보다 빠름.\n",
    "- 활용: 실시간 처리보다는 높은 정확도를 요구하는 객체 탐지에서 활용됨.,\"\"\"\n",
    "},\n",
    "\n",
    "{\n",
    "\"question\": \"SSD의 특징은 뭐야?\",\n",
    "\"answer\": \"\"\"\n",
    "◦ 특징:\n",
    "1. One-stage Detector: Region Proposal 없이 단 한 번의 Forward Pass로 객체 탐지를 수행함. 속도가 빠르고 실시간 탐지가 가능함\n",
    "2. Multi-scale Feature Maps: 여러 계층의 Feature Map에서 Bounding Box를 예측하여 다양한 크기의 객체 탐지 가능, 작은 객체 탐지를 개선하기 위해 저해상도 + 고해상도 Feature Map을 활용함.\n",
    "3. Anchor Box 활용: Faster R-CNN과 유사하게 다양한 크기와 비율의 앵커 박스(기본 박스)를 사용하여 여러 객체를 동시에 탐지함. 하지만 RPN을 사용하지 않고 CNN이 직접 여러 박스를 예측함.\n",
    "4. End-to-End 학습 가능: Faster R-CNN과 달리 별도의 RPN 없이 단일 네트워크로 객체 탐지와 분류를 동시에 학습 가능함.\n",
    "\n",
    "◦ 구조:\n",
    "1. Backbone CNN (ResNet, VGG 등) → Feature Map 생성\n",
    "2. Multi-scale Feature Maps 활용 → 다양한 크기의 객체를 감지하기 위해 여러 층의 Feature Map을 사용\n",
    "3. Anchor Box 기반 예측 → 각 Feature Map의 셀에서 여러 개의 Bounding Box를 동시에 예측\n",
    "4. Non-Maximum Suppression (NMS) → 중복된 Bounding Box를 제거하여 최종 탐지 결과 출력\n",
    "\n",
    "◦ 성능 비교:\n",
    "- 정확도: Faster R-CNN보다 약간 낮지만, YOLO보다는 비슷하거나 높은 성능을 보임.\n",
    "- 속도: Faster R-CNN보다 빠르며, YOLO보다는 약간 느릴 수 있음.\n",
    "- 활용: 실시간 객체 탐지(자율주행, 감시 시스템 등)에 적합하며, 속도와 정확도 균형이 필요할 때 유용함.\n",
    "\"\"\",\n",
    "},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Faster R-CNN의 특징은 뭐야\\nAI: \\n◦ 특징:\\n1. Region Proposal Network (RPN) 사용: CNN 기반 RPN을 활용하여 관심 영역을 빠르게 생성함.\\n2. End-to-End 학습 가능: Region Proposal과 Classification을 하나의 네트워크에서 학습할 수 있음.\\n3. Feature Map 공유: Backbone CNN을 공유하여 연산량을 줄이고 속도를 개선함.\\n4. Anchor Box 활용: 다양한 크기의 객체를 탐지할 수 있도록 앵커 박스를 사용함.,\\n\\n◦ 구조:\\n1. Backbone CNN (ResNet, VGG 등) → Feature Map 생성\\n2. Region Proposal Network (RPN) → 관심 영역(Region Proposal) 예측\\n3. ROI Pooling → 관심 영역을 동일한 크기로 변환\\n4. Fully Connected Layers → Classification + Bounding Box Regression 수행,\\n\\n◦ 성능 비교:\\n- 정확도: Faster R-CNN은 YOLO보다 높은 정확도를 가짐.\\n- 속도: YOLO, SSD에 비해 느리지만 Fast R-CNN보다 빠름.\\n- 활용: 실시간 처리보다는 높은 정확도를 요구하는 객체 탐지에서 활용됨.,\\n\\nHuman: YOLOv3의 특징은 뭐야'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import example_selector\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "        return [choice(self.examples)]\n",
    "        \n",
    "example_prompt_1 = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples = examples,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt_1,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: {model}의 특징은 뭐야\",\n",
    "    input_variables=[\"model\"]\n",
    ")\n",
    "\n",
    "prompt.format(model=\"YOLOv3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YOLOv3의 특징을 설명해줘'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "# prompt = load_prompt(\"./prompt.json\")\n",
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "prompt.format(model=\"YOLOv3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PipeLine\n",
    "> - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You are a role playing assistant.\n",
    "And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "This is an example of how you talk:\n",
    "\n",
    "Human: {example_question}\n",
    "You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Start now!\n",
    "\n",
    "Human: {question}\n",
    "You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "{intro}\n",
    "\n",
    "{example}\n",
    "\n",
    "{start}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The treatment for a cold typically involves rest, staying hydrated, and over-the-counter medications to help alleviate symptoms such as fever, congestion, and cough. It's important to get plenty of rest and drink lots of fluids to help your body fight off the virus causing the cold. If your symptoms persist or worsen, it's always best to consult with a healthcare professional for further guidance."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"The treatment for a cold typically involves rest, staying hydrated, and over-the-counter medications to help alleviate symptoms such as fever, congestion, and cough. It's important to get plenty of rest and drink lots of fluids to help your body fight off the virus causing the cold. If your symptoms persist or worsen, it's always best to consult with a healthcare professional for further guidance.\")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start),\n",
    "]\n",
    "full_prompt = PipelinePromptTemplate(final_prompt=final, pipeline_prompts=prompts)\n",
    "\n",
    "chain = full_prompt | chat\n",
    "chain.invoke({\n",
    "    \"character\":\"doctor\", \n",
    "    \"example_question\":\"What is the treatment for a cold?\", \n",
    "    \"example_answer\":\"The treatment for a cold is rest and hydration.\", \n",
    "    \"question\":\"What is the treatment for a cold?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cashing\n",
    "> - LLM의 응답을 저장할 수 있다.\n",
    "> - 이미 답변한 답을 캐싱을 이용해 저장하여 재사용할 수 있다.\n",
    "> - 비용을 아끼는 데 도움"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: 객체 탐지 모델 중 SSD의 특징은 뭐야\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [4.40s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"SSD (Single Shot Multibox Detector)의 특징은 다음과 같다.\\n\\n1. 실시간 객체 탐지: SSD는 높은 정확도로 다양한 크기의 객체를 실시간으로 탐지할 수 있다.\\n\\n2. 다양한 크기의 객체 탐지: SSD는 다양한 크기의 객체를 효과적으로 탐지할 수 있는 다양한 크기의 feature map을 사용한다.\\n\\n3. 단일 네트워크 구조: SSD는 객체 탐지를 위한 단일 네트워크 구조로 이루어져 있어서 간단하고 효율적이다.\\n\\n4. 다양한 종류의 객체 탐지: SSD는 다양한 클래스의 객체를 탐지할 수 있으며, 다중 객체 탐지에도 효과적이다.\\n\\n5. 경계 상자 예측: SSD는 객체의 경계 상자와 클래스를 동시에 예측하여 객체 탐지 성능을 향상시킨다.\\n\\n6. 다양한 이미지 크기에 대응: SSD는 입력 이미지의 크기에 상관없이 객체를 탐지할 수 있으며, 다양한 해상도의 이미지에 대응할 수 있다. \\n\\n7. 경량 모델: SSD는 경량 모델로서 빠른 속도로 객체를 탐지할 수 있으며, 임베디드 시스템이나 모바일 기기에서도 효율적으로 동작한다.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"SSD (Single Shot Multibox Detector)의 특징은 다음과 같다.\\n\\n1. 실시간 객체 탐지: SSD는 높은 정확도로 다양한 크기의 객체를 실시간으로 탐지할 수 있다.\\n\\n2. 다양한 크기의 객체 탐지: SSD는 다양한 크기의 객체를 효과적으로 탐지할 수 있는 다양한 크기의 feature map을 사용한다.\\n\\n3. 단일 네트워크 구조: SSD는 객체 탐지를 위한 단일 네트워크 구조로 이루어져 있어서 간단하고 효율적이다.\\n\\n4. 다양한 종류의 객체 탐지: SSD는 다양한 클래스의 객체를 탐지할 수 있으며, 다중 객체 탐지에도 효과적이다.\\n\\n5. 경계 상자 예측: SSD는 객체의 경계 상자와 클래스를 동시에 예측하여 객체 탐지 성능을 향상시킨다.\\n\\n6. 다양한 이미지 크기에 대응: SSD는 입력 이미지의 크기에 상관없이 객체를 탐지할 수 있으며, 다양한 해상도의 이미지에 대응할 수 있다. \\n\\n7. 경량 모델: SSD는 경량 모델로서 빠른 속도로 객체를 탐지할 수 있으며, 임베디드 시스템이나 모바일 기기에서도 효율적으로 동작한다.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 27,\n",
      "      \"completion_tokens\": 414,\n",
      "      \"total_tokens\": 441,\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"cached_tokens\": 0,\n",
      "        \"audio_tokens\": 0\n",
      "      },\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SSD (Single Shot Multibox Detector)의 특징은 다음과 같다.\\n\\n1. 실시간 객체 탐지: SSD는 높은 정확도로 다양한 크기의 객체를 실시간으로 탐지할 수 있다.\\n\\n2. 다양한 크기의 객체 탐지: SSD는 다양한 크기의 객체를 효과적으로 탐지할 수 있는 다양한 크기의 feature map을 사용한다.\\n\\n3. 단일 네트워크 구조: SSD는 객체 탐지를 위한 단일 네트워크 구조로 이루어져 있어서 간단하고 효율적이다.\\n\\n4. 다양한 종류의 객체 탐지: SSD는 다양한 클래스의 객체를 탐지할 수 있으며, 다중 객체 탐지에도 효과적이다.\\n\\n5. 경계 상자 예측: SSD는 객체의 경계 상자와 클래스를 동시에 예측하여 객체 탐지 성능을 향상시킨다.\\n\\n6. 다양한 이미지 크기에 대응: SSD는 입력 이미지의 크기에 상관없이 객체를 탐지할 수 있으며, 다양한 해상도의 이미지에 대응할 수 있다. \\n\\n7. 경량 모델: SSD는 경량 모델로서 빠른 속도로 객체를 탐지할 수 있으며, 임베디드 시스템이나 모바일 기기에서도 효율적으로 동작한다.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "# set_llm_cache(InMemoryCache()) # 모든 response가 메모리에 저장됨\n",
    "set_llm_cache(SQLiteCache(\"cache.db\")) # 모든 response가 SQLite DB에 저장됨\n",
    "\n",
    "# set_debug(True) # 디버그 모드 활성화\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5)\n",
    "chat.predict(\"객체 탐지 모델 중 SSD의 특징은 뭐야\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### serialization\n",
    "> - 데이터 직렬화\n",
    "> - 메모리를 디스크에 저장하거나 네트워크 통신에 사용하기 위한 형식으로 변환하는 것\n",
    "> - deserialization = 역직렬화: 디스크에 저장한 데이터를 읽거나 네트워크 통신으로 받은 데이터를 메모리에 쓸 수 있도록 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "    a = chat.predict(\"객체 탐지 모델 중 SSD의 특징은 뭐야\")\n",
    "    b = chat.predict(\"객체 탐지 모델 중 RetinaNet의 특징은 뭐야\")\n",
    "    print(a, '\\n\\n', b, '\\n')\n",
    "    print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "chat = OpenAI(temperature=0.5, max_tokens=1000, model=\"gpt-3.5-turbo-0125\")\n",
    "# chat.save(\"model.json\")\n",
    "# chat = load_llm(\"model.json\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
